{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM for Multivariate Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-11-02</th>\n",
       "      <td>41.650002</td>\n",
       "      <td>42.125000</td>\n",
       "      <td>41.320000</td>\n",
       "      <td>42.027500</td>\n",
       "      <td>1.655736e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-03</th>\n",
       "      <td>43.500000</td>\n",
       "      <td>43.564999</td>\n",
       "      <td>42.779999</td>\n",
       "      <td>43.125000</td>\n",
       "      <td>2.375944e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-04</th>\n",
       "      <td>43.364166</td>\n",
       "      <td>43.625833</td>\n",
       "      <td>42.829999</td>\n",
       "      <td>43.270833</td>\n",
       "      <td>2.050980e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-05</th>\n",
       "      <td>43.228333</td>\n",
       "      <td>43.686667</td>\n",
       "      <td>42.880000</td>\n",
       "      <td>43.416667</td>\n",
       "      <td>1.726016e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-06</th>\n",
       "      <td>43.092499</td>\n",
       "      <td>43.747501</td>\n",
       "      <td>42.930000</td>\n",
       "      <td>43.562500</td>\n",
       "      <td>1.401052e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-28</th>\n",
       "      <td>148.199997</td>\n",
       "      <td>157.500000</td>\n",
       "      <td>147.820007</td>\n",
       "      <td>155.740005</td>\n",
       "      <td>1.647624e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-29</th>\n",
       "      <td>149.853333</td>\n",
       "      <td>156.413335</td>\n",
       "      <td>149.186671</td>\n",
       "      <td>154.940002</td>\n",
       "      <td>1.424893e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-30</th>\n",
       "      <td>151.506668</td>\n",
       "      <td>155.326670</td>\n",
       "      <td>150.553335</td>\n",
       "      <td>154.139999</td>\n",
       "      <td>1.202163e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-31</th>\n",
       "      <td>153.160004</td>\n",
       "      <td>154.240005</td>\n",
       "      <td>151.919998</td>\n",
       "      <td>153.339996</td>\n",
       "      <td>9.794320e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-01</th>\n",
       "      <td>155.080002</td>\n",
       "      <td>155.449997</td>\n",
       "      <td>149.130005</td>\n",
       "      <td>150.649994</td>\n",
       "      <td>8.032140e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1826 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Open        High         Low       Close        Volume\n",
       "Date                                                                    \n",
       "2017-11-02   41.650002   42.125000   41.320000   42.027500  1.655736e+08\n",
       "2017-11-03   43.500000   43.564999   42.779999   43.125000  2.375944e+08\n",
       "2017-11-04   43.364166   43.625833   42.829999   43.270833  2.050980e+08\n",
       "2017-11-05   43.228333   43.686667   42.880000   43.416667  1.726016e+08\n",
       "2017-11-06   43.092499   43.747501   42.930000   43.562500  1.401052e+08\n",
       "...                ...         ...         ...         ...           ...\n",
       "2022-10-28  148.199997  157.500000  147.820007  155.740005  1.647624e+08\n",
       "2022-10-29  149.853333  156.413335  149.186671  154.940002  1.424893e+08\n",
       "2022-10-30  151.506668  155.326670  150.553335  154.139999  1.202163e+08\n",
       "2022-10-31  153.160004  154.240005  151.919998  153.339996  9.794320e+07\n",
       "2022-11-01  155.080002  155.449997  149.130005  150.649994  8.032140e+07\n",
       "\n",
       "[1826 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df: pd.DataFrame = pd.read_pickle(\"../../data/demo.pkl\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Open', 'High', 'Low', 'Close', 'Volume'], dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode Fields in a Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Close', 'High', 'Low', 'Open', 'Volume'], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(df.columns)\n",
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['High'], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.inverse_transform([1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.20275002e+01, 4.21250000e+01, 4.13199997e+01, 4.16500015e+01,\n",
       "        1.65573600e+08],\n",
       "       [4.31250000e+01, 4.35649986e+01, 4.27799988e+01, 4.35000000e+01,\n",
       "        2.37594400e+08],\n",
       "       [4.32708333e+01, 4.36258329e+01, 4.28299993e+01, 4.33641663e+01,\n",
       "        2.05098000e+08],\n",
       "       ...,\n",
       "       [1.54139999e+02, 1.55326670e+02, 1.50553335e+02, 1.51506668e+02,\n",
       "        1.20216267e+08],\n",
       "       [1.53339996e+02, 1.54240005e+02, 1.51919998e+02, 1.53160004e+02,\n",
       "        9.79432000e+07],\n",
       "       [1.50649994e+02, 1.55449997e+02, 1.49130005e+02, 1.55080002e+02,\n",
       "        8.03214000e+07]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df[le.classes_].to_numpy()\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 42.02750015,  41.65000153,  42.125     ],\n",
       "       [ 43.125     ,  43.5       ,  43.56499863],\n",
       "       [ 43.27083333,  43.36416626,  43.62583288],\n",
       "       ...,\n",
       "       [154.13999939, 151.50666809, 155.32667033],\n",
       "       [153.33999634, 153.16000366, 154.24000549],\n",
       "       [150.6499939 , 155.08000183, 155.44999695]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:, le.transform([\"Close\", \"Open\", \"High\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Close</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-11-02</th>\n",
       "      <td>42.027500</td>\n",
       "      <td>41.650002</td>\n",
       "      <td>42.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-03</th>\n",
       "      <td>43.125000</td>\n",
       "      <td>43.500000</td>\n",
       "      <td>43.564999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-04</th>\n",
       "      <td>43.270833</td>\n",
       "      <td>43.364166</td>\n",
       "      <td>43.625833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-05</th>\n",
       "      <td>43.416667</td>\n",
       "      <td>43.228333</td>\n",
       "      <td>43.686667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-06</th>\n",
       "      <td>43.562500</td>\n",
       "      <td>43.092499</td>\n",
       "      <td>43.747501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-28</th>\n",
       "      <td>155.740005</td>\n",
       "      <td>148.199997</td>\n",
       "      <td>157.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-29</th>\n",
       "      <td>154.940002</td>\n",
       "      <td>149.853333</td>\n",
       "      <td>156.413335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-30</th>\n",
       "      <td>154.139999</td>\n",
       "      <td>151.506668</td>\n",
       "      <td>155.326670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-31</th>\n",
       "      <td>153.339996</td>\n",
       "      <td>153.160004</td>\n",
       "      <td>154.240005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-01</th>\n",
       "      <td>150.649994</td>\n",
       "      <td>155.080002</td>\n",
       "      <td>155.449997</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1826 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Close        Open        High\n",
       "Date                                          \n",
       "2017-11-02   42.027500   41.650002   42.125000\n",
       "2017-11-03   43.125000   43.500000   43.564999\n",
       "2017-11-04   43.270833   43.364166   43.625833\n",
       "2017-11-05   43.416667   43.228333   43.686667\n",
       "2017-11-06   43.562500   43.092499   43.747501\n",
       "...                ...         ...         ...\n",
       "2022-10-28  155.740005  148.199997  157.500000\n",
       "2022-10-29  154.940002  149.853333  156.413335\n",
       "2022-10-30  154.139999  151.506668  155.326670\n",
       "2022-10-31  153.339996  153.160004  154.240005\n",
       "2022-11-01  150.649994  155.080002  155.449997\n",
       "\n",
       "[1826 rows x 3 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[[\"Close\", \"Open\", \"High\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            input_size: int, hidden_size: int,\n",
    "            num_layers: int, output_size: int\n",
    "        ):\n",
    "        \n",
    "        # initialize super class\n",
    "        super().__init__()\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.output_size = output_size\n",
    "\n",
    "        # LSTM layer\n",
    "        self.lstm = nn.LSTM(self.input_size, self.hidden_size, self.num_layers, batch_first=True)\n",
    "\n",
    "        # fully connected layer\n",
    "        self.fc = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \n",
    "        # output has shape (N, L, H)\n",
    "        # h_n has shape (num_layers, N, H)\n",
    "        #\n",
    "        # where N is the batch size\n",
    "        # L is the sequence length\n",
    "        # and H is the hidden size\n",
    "        # output, (h_n, c_n) = self.lstm.forward(x, (h0.detach(), c0.detach()))\n",
    "        output, (h_n, c_n) = self.lstm.forward(x)\n",
    "\n",
    "        # in fact, we want the last hidden value\n",
    "        # from the last LSTM layer, i.e., h_n[-1, :, :]\n",
    "        h = h_n[-1, :, :]\n",
    "        \n",
    "        # get predicted value from\n",
    "        # the fully connected layer\n",
    "        y = self.fc.forward(h)\n",
    "\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [3, 4],\n",
       "       [5, 6]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.array([\n",
    "    [1, 2],\n",
    "    [3, 4]\n",
    "])\n",
    "\n",
    "B = np.array([\n",
    "    [5, 6]\n",
    "])\n",
    "\n",
    "np.concatenate((A, B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can only concatenate list (not \"int\") to list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/isaac/Documents/HKU/programming-for-data-science/stox/book/closing-price-prediction/multivariate-time-series.ipynb Cell 14\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/isaac/Documents/HKU/programming-for-data-science/stox/book/closing-price-prediction/multivariate-time-series.ipynb#X16sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m [\u001b[39m1\u001b[39;49m, \u001b[39m2\u001b[39;49m] \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m\n",
      "\u001b[0;31mTypeError\u001b[0m: can only concatenate list (not \"int\") to list"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('stox')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b381d2fe9444cf1cecb971d5b2371557f7ae9b538a405ed569cd73f1b37c2a0c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
